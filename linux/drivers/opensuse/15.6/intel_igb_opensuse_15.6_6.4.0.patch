diff -rup /home_local/burger_r/opensuse/kernel/drivers/net/ethernet/intel/igb/igb.h 6.4.0/intel/igb/igb.h
--- /home_local/burger_r/opensuse/kernel/drivers/net/ethernet/intel/igb/igb.h	2024-11-28 06:57:33.117781519 +0100
+++ 6.4.0/intel/igb/igb.h	2024-11-27 12:32:25.261223011 +0100
@@ -21,6 +21,9 @@
 
 #include <net/xdp.h>
 
+#include "ethercat_device.h"
+#include "ethercat_device_ioctl.h"
+
 struct igb_adapter;
 
 #define E1000_PCS_CFG_IGN_SD	1
@@ -666,6 +669,9 @@ struct igb_adapter {
 	struct vf_mac_filter *vf_mac_list;
 	/* lock for VF resources */
 	spinlock_t vfs_lock;
+
+	bool is_ecat;
+	struct ethercat_device *ecat_dev;
 };
 
 /* flags controlling PTP/1588 function */
diff -rup /home_local/burger_r/opensuse/kernel/drivers/net/ethernet/intel/igb/igb_main.c 6.4.0/intel/igb/igb_main.c
--- /home_local/burger_r/opensuse/kernel/drivers/net/ethernet/intel/igb/igb_main.c	2024-11-28 06:57:33.117781519 +0100
+++ 6.4.0/intel/igb/igb_main.c	2024-11-27 12:32:25.282223005 +0100
@@ -33,7 +33,6 @@
 #include <linux/bpf_trace.h>
 #include <linux/pm_runtime.h>
 #include <linux/etherdevice.h>
-#include <linux/lockdep.h>
 #ifdef CONFIG_IGB_DCA
 #include <linux/dca.h>
 #endif
@@ -50,9 +49,9 @@ enum tx_queue_prio {
 	TX_QUEUE_PRIO_LOW,
 };
 
-char igb_driver_name[] = "igb";
+char igb_driver_name[] = "igb-ethercat";
 static const char igb_driver_string[] =
-				"Intel(R) Gigabit Ethernet Network Driver";
+				"Intel(R) Gigabit Ethernet Network Driver (EtherCAT enabled)";
 static const char igb_copyright[] =
 				"Copyright (c) 2007-2014 Intel Corporation.";
 
@@ -207,6 +206,16 @@ module_param(max_vfs, uint, 0);
 MODULE_PARM_DESC(max_vfs, "Maximum number of virtual functions to allocate per physical function");
 #endif /* CONFIG_PCI_IOV */
 
+#define ETHERCAT_MAC_ADDR_SIZE 10
+static char * ethercat_mac_addr[ETHERCAT_MAC_ADDR_SIZE];
+static int ethercat_mac_addr_count;
+module_param_array(ethercat_mac_addr, charp, &ethercat_mac_addr_count,  0660);
+MODULE_PARM_DESC(ethercat_mac_addr, "List of MAC addresses to use as EtherCAT device");
+
+static unsigned int ethercat_polling;
+module_param(ethercat_polling, uint, 0);
+MODULE_PARM_DESC(ethercat_polling, "Set interface to polling mode (no interrupt) for EtherCAT case");
+
 static pci_ers_result_t igb_io_error_detected(struct pci_dev *,
 		     pci_channel_state_t);
 static pci_ers_result_t igb_io_slot_reset(struct pci_dev *);
@@ -236,6 +245,7 @@ static struct pci_driver igb_driver = {
 MODULE_AUTHOR("Intel Corporation, <e1000-devel@lists.sourceforge.net>");
 MODULE_DESCRIPTION("Intel(R) Gigabit Ethernet Network Driver");
 MODULE_LICENSE("GPL v2");
+MODULE_SOFTDEP("pre: ethercat");
 
 #define DEFAULT_MSG_ENABLE (NETIF_MSG_DRV|NETIF_MSG_PROBE|NETIF_MSG_LINK)
 static int debug = -1;
@@ -363,7 +373,7 @@ static void igb_dump(struct igb_adapter
 	u32 staterr;
 	u16 i, n;
 
-	if (!netif_msg_hw(adapter))
+	if (!adapter->is_ecat && !netif_msg_hw(adapter))
 		return;
 
 	/* Print netdevice Info */
@@ -383,7 +393,7 @@ static void igb_dump(struct igb_adapter
 	}
 
 	/* Print TX Ring Summary */
-	if (!netdev || !netif_running(netdev))
+	if (!adapter->is_ecat && (!netdev || !netif_running(netdev)))
 		goto exit;
 
 	dev_info(&adapter->pdev->dev, "TX Rings Summary\n");
@@ -401,7 +411,7 @@ static void igb_dump(struct igb_adapter
 	}
 
 	/* Print TX Rings */
-	if (!netif_msg_tx_done(adapter))
+	if (!adapter->is_ecat && !netif_msg_tx_done(adapter))
 		goto rx_ring_summary;
 
 	dev_info(&adapter->pdev->dev, "TX Rings Dump\n");
@@ -933,9 +943,13 @@ static int igb_request_msix(struct igb_a
 	unsigned int num_q_vectors = adapter->num_q_vectors;
 	struct net_device *netdev = adapter->netdev;
 	int i, err = 0, vector = 0, free_vector = 0;
+	unsigned long irq_flags = 0;
+	if (adapter->is_ecat) {
+		irq_flags = IRQF_NO_THREAD;
+	}
 
 	err = request_irq(adapter->msix_entries[vector].vector,
-			  igb_msix_other, 0, netdev->name, adapter);
+			  igb_msix_other, irq_flags, netdev->name, adapter);
 	if (err)
 		goto err_out;
 
@@ -965,7 +979,7 @@ static int igb_request_msix(struct igb_a
 			sprintf(q_vector->name, "%s-unused", netdev->name);
 
 		err = request_irq(adapter->msix_entries[vector].vector,
-				  igb_msix_ring, 0, q_vector->name,
+				  igb_msix_ring, irq_flags, q_vector->name,
 				  q_vector);
 		if (err)
 			goto err_free;
@@ -1031,8 +1045,9 @@ static void igb_reset_q_vector(struct ig
 	if (q_vector->rx.ring)
 		adapter->rx_ring[q_vector->rx.ring->queue_index] = NULL;
 
-	netif_napi_del(&q_vector->napi);
-
+	if (unlikely(!adapter->is_ecat)) {
+		netif_napi_del(&q_vector->napi);
+	}
 }
 
 static void igb_reset_interrupt_capability(struct igb_adapter *adapter)
@@ -1215,8 +1230,10 @@ static int igb_alloc_q_vector(struct igb
 	if (!q_vector)
 		return -ENOMEM;
 
-	/* initialize NAPI */
-	netif_napi_add(adapter->netdev, &q_vector->napi, igb_poll);
+	if (unlikely(!adapter->is_ecat)) {
+		/* initialize NAPI */
+		netif_napi_add(adapter->netdev, &q_vector->napi, igb_poll);
+	}
 
 	/* tie q_vector and adapter together */
 	adapter->q_vector[v_idx] = q_vector;
@@ -1413,8 +1430,16 @@ static int igb_request_irq(struct igb_ad
 	struct net_device *netdev = adapter->netdev;
 	struct pci_dev *pdev = adapter->pdev;
 	int err = 0;
+	unsigned long irq_flags = 0;
+	if (adapter->is_ecat) {
+		irq_flags = IRQF_NO_THREAD;
+	}
 
 	if (adapter->flags & IGB_FLAG_HAS_MSIX) {
+        if ((adapter->is_ecat) && (ethercat_polling != 0)) {
+            goto request_done;
+        }
+
 		err = igb_request_msix(adapter);
 		if (!err)
 			goto request_done;
@@ -1434,8 +1459,12 @@ static int igb_request_irq(struct igb_ad
 
 	igb_assign_vector(adapter->q_vector[0], 0);
 
+    if ((adapter->is_ecat) && (ethercat_polling != 0)) {
+        goto request_done;
+    }
+
 	if (adapter->flags & IGB_FLAG_HAS_MSI) {
-		err = request_irq(pdev->irq, igb_intr_msi, 0,
+		err = request_irq(pdev->irq, igb_intr_msi, irq_flags,
 				  netdev->name, adapter);
 		if (!err)
 			goto request_done;
@@ -1445,7 +1474,11 @@ static int igb_request_irq(struct igb_ad
 		adapter->flags &= ~IGB_FLAG_HAS_MSI;
 	}
 
-	err = request_irq(pdev->irq, igb_intr, IRQF_SHARED,
+	if (!adapter->is_ecat) {
+		irq_flags = IRQF_SHARED;
+	}
+
+	err = request_irq(pdev->irq, igb_intr, irq_flags,
 			  netdev->name, adapter);
 
 	if (err)
@@ -1458,6 +1491,10 @@ request_done:
 
 static void igb_free_irq(struct igb_adapter *adapter)
 {
+	if ((adapter->is_ecat) && (ethercat_polling != 0)) {
+		return;
+	}
+
 	if (adapter->flags & IGB_FLAG_HAS_MSIX) {
 		int vector = 0, i;
 
@@ -1701,7 +1738,7 @@ static void igb_config_tx_modes(struct i
 	 * with HIGH PRIO. If none is, then configure them with LOW PRIO and
 	 * as SP.
 	 */
-	if (ring->cbs_enable || ring->launchtime_enable) {
+	if (adapter->is_ecat || ring->cbs_enable || ring->launchtime_enable) {
 		set_tx_desc_fetch_prio(hw, queue, TX_QUEUE_PRIO_HIGH);
 		set_queue_mode(hw, queue, QUEUE_MODE_STREAM_RESERVATION);
 	} else {
@@ -1710,7 +1747,7 @@ static void igb_config_tx_modes(struct i
 	}
 
 	/* If CBS is enabled, set DataTranARB and config its parameters. */
-	if (ring->cbs_enable || queue == 0) {
+	if (adapter->is_ecat || ring->cbs_enable || queue == 0) {
 		/* i210 does not allow the queue 0 to be in the Strict
 		 * Priority mode while the Qav mode is enabled, so,
 		 * instead of disabling strict priority mode, we give
@@ -2128,8 +2165,10 @@ int igb_up(struct igb_adapter *adapter)
 
 	clear_bit(__IGB_DOWN, &adapter->state);
 
-	for (i = 0; i < adapter->num_q_vectors; i++)
-		napi_enable(&(adapter->q_vector[i]->napi));
+	if (unlikely(!adapter->is_ecat)) {
+		for (i = 0; i < adapter->num_q_vectors; i++)
+			napi_enable(&(adapter->q_vector[i]->napi));
+	}
 
 	if (adapter->flags & IGB_FLAG_HAS_MSIX)
 		igb_configure_msix(adapter);
@@ -2149,7 +2188,9 @@ int igb_up(struct igb_adapter *adapter)
 		wr32(E1000_CTRL_EXT, reg_data);
 	}
 
-	netif_tx_start_all_queues(adapter->netdev);
+	if (!adapter->is_ecat) {
+		netif_tx_start_all_queues(adapter->netdev);
+	}
 
 	/* start the watchdog. */
 	hw->mac.get_link_status = 1;
@@ -2181,8 +2222,10 @@ void igb_down(struct igb_adapter *adapte
 
 	igb_nfc_filter_exit(adapter);
 
-	netif_carrier_off(netdev);
-	netif_tx_stop_all_queues(netdev);
+	if (!adapter->is_ecat) {
+		netif_carrier_off(netdev);
+		netif_tx_stop_all_queues(netdev);
+	}
 
 	/* disable transmits in the hardware */
 	tctl = rd32(E1000_TCTL);
@@ -2196,10 +2239,12 @@ void igb_down(struct igb_adapter *adapte
 
 	adapter->flags &= ~IGB_FLAG_NEED_LINK_UPDATE;
 
-	for (i = 0; i < adapter->num_q_vectors; i++) {
-		if (adapter->q_vector[i]) {
-			napi_synchronize(&adapter->q_vector[i]->napi);
-			napi_disable(&adapter->q_vector[i]->napi);
+	if (unlikely(!adapter->is_ecat)) {
+		for (i = 0; i < adapter->num_q_vectors; i++) {
+			if (adapter->q_vector[i]) {
+				napi_synchronize(&adapter->q_vector[i]->napi);
+				napi_disable(&adapter->q_vector[i]->napi);
+			}
 		}
 	}
 
@@ -2445,8 +2490,11 @@ void igb_reset(struct igb_adapter *adapt
 			break;
 		}
 	}
-	if (!netif_running(adapter->netdev))
-		igb_power_down_link(adapter);
+
+	if (!adapter->is_ecat) {
+		if (!netif_running(adapter->netdev))
+			igb_power_down_link(adapter);
+	}
 
 	igb_update_mng_vlan(adapter);
 
@@ -2940,11 +2988,8 @@ static int igb_xdp(struct net_device *de
 	}
 }
 
-/* This function assumes __netif_tx_lock is held by the caller. */
 static void igb_xdp_ring_update_tail(struct igb_ring *ring)
 {
-	lockdep_assert_held(&txring_txq(ring)->_xmit_lock);
-
 	/* Force memory writes to complete before letting h/w know there
 	 * are new descriptors to fetch.
 	 */
@@ -3029,11 +3074,11 @@ static int igb_xdp_xmit(struct net_devic
 		nxmit++;
 	}
 
+	__netif_tx_unlock(nq);
+
 	if (unlikely(flags & XDP_XMIT_FLUSH))
 		igb_xdp_ring_update_tail(tx_ring);
 
-	__netif_tx_unlock(nq);
-
 	return nxmit;
 }
 
@@ -3191,6 +3236,35 @@ static s32 igb_init_i2c(struct igb_adapt
 	return status;
 }
 
+static int parse_macaddr(const char *macstr, char *dev_addr)
+{
+	int i, h, l;
+
+	for (i = 0; i < 6; i++) {
+		h = hex_to_bin(*macstr);
+		if (h == -1)
+			goto err;
+		macstr++;
+
+		l = hex_to_bin(*macstr);
+		if (l == -1)
+			goto err;
+		macstr++;
+
+		if (i != 5) {
+			if (*macstr != ':')
+				goto err;
+			macstr++;
+		}
+		dev_addr[i] = (h << 4) + l;
+	}
+	if (is_valid_ether_addr(dev_addr))
+		return 0;
+
+err:
+	return -EINVAL;
+}
+
 /**
  *  igb_probe - Device Initialization Routine
  *  @pdev: PCI device information struct
@@ -3213,6 +3287,7 @@ static int igb_probe(struct pci_dev *pde
 	const struct e1000_info *ei = igb_info_tbl[ent->driver_data];
 	u8 part_str[E1000_PBANUM_LENGTH];
 	int err;
+	int cnt = 0;
 
 	/* Catch broken hardware that put the wrong VF device ID in
 	 * the PCIe SR-IOV capability.
@@ -3253,6 +3328,8 @@ static int igb_probe(struct pci_dev *pde
 	adapter = netdev_priv(netdev);
 	adapter->netdev = netdev;
 	adapter->pdev = pdev;
+	adapter->is_ecat = false;
+	adapter->ecat_dev = NULL;
 	hw = &adapter->hw;
 	hw->back = adapter;
 	adapter->msg_enable = netif_msg_init(debug, DEFAULT_MSG_ENABLE);
@@ -3535,13 +3612,53 @@ static int igb_probe(struct pci_dev *pde
 	 */
 	igb_get_hw_control(adapter);
 
-	strcpy(netdev->name, "eth%d");
-	err = register_netdev(netdev);
-	if (err)
-		goto err_register;
+	/* check if we should use this one as EtherCAT device 
+	*/ 
+	if (ethercat_mac_addr_count > 0) {
+		for (cnt = 0; cnt < ethercat_mac_addr_count; ++cnt) {
+			char ethercat_dev_addr[6];
+			parse_macaddr(ethercat_mac_addr[cnt], ethercat_dev_addr);
+
+			if (ether_addr_equal(netdev->dev_addr, ethercat_dev_addr)) {
+				int i = 0;
+
+				dev_info(&pdev->dev, "attaching as EtherCAT interface\n");
+				adapter->is_ecat = true;
+				adapter->ecat_dev = ethercat_device_create(netdev);
+
+				/* set low ITR values */
+				adapter->rx_itr_setting = 0;
+				adapter->tx_itr_setting = 0;
+
+				/* If ITR is disabled, disable DMAC */
+				if (adapter->flags & IGB_FLAG_DMAC)
+					adapter->flags &= ~IGB_FLAG_DMAC;
+
+				for (i = 0; i < adapter->num_q_vectors; i++) {
+					struct igb_q_vector *q_vector = adapter->q_vector[i];
+					q_vector->tx.work_limit = adapter->tx_work_limit;
+					if (q_vector->rx.ring)
+						q_vector->itr_val = adapter->rx_itr_setting;
+					else
+						q_vector->itr_val = adapter->tx_itr_setting;
 
-	/* carrier off reporting is important to ethtool even BEFORE open */
-	netif_carrier_off(netdev);
+					/* configure q_vector to set itr on next interrupt */
+					q_vector->set_itr = 1;
+				}
+				break;
+			}
+		}
+	}
+
+	if (!adapter->is_ecat) {
+		strcpy(netdev->name, "eth%d");
+		err = register_netdev(netdev);
+		if (err)
+			goto err_register;
+
+		/* carrier off reporting is important to ethtool even BEFORE open */
+		netif_carrier_off(netdev);
+	}
 
 #ifdef CONFIG_IGB_DCA
 	if (dca_add_requester(&pdev->dev) == 0) {
@@ -3875,6 +3992,10 @@ static void igb_remove(struct pci_dev *p
 	struct igb_adapter *adapter = netdev_priv(netdev);
 	struct e1000_hw *hw = &adapter->hw;
 
+	if (adapter->ecat_dev) {
+		ethercat_device_destroy(adapter->ecat_dev);
+	}
+
 	pm_runtime_get_noresume(&pdev->dev);
 #ifdef CONFIG_IGB_HWMON
 	igb_sysfs_exit(adapter);
@@ -3909,7 +4030,9 @@ static void igb_remove(struct pci_dev *p
 	igb_disable_sriov(pdev, false);
 #endif
 
-	unregister_netdev(netdev);
+	if (!adapter->is_ecat) {
+		unregister_netdev(netdev);
+	}
 
 	igb_clear_interrupt_scheme(adapter);
 
@@ -4152,7 +4275,9 @@ static int __igb_open(struct net_device
 	if (!resuming)
 		pm_runtime_get_sync(&pdev->dev);
 
-	netif_carrier_off(netdev);
+	if (!adapter->is_ecat) {
+		netif_carrier_off(netdev);
+	}
 
 	/* allocate transmit descriptors */
 	err = igb_setup_all_tx_resources(adapter);
@@ -4177,22 +4302,26 @@ static int __igb_open(struct net_device
 	if (err)
 		goto err_req_irq;
 
-	/* Notify the stack of the actual queue counts. */
-	err = netif_set_real_num_tx_queues(adapter->netdev,
-					   adapter->num_tx_queues);
-	if (err)
-		goto err_set_queues;
+	if (!adapter->is_ecat) {
+		/* Notify the stack of the actual queue counts. */
+		err = netif_set_real_num_tx_queues(adapter->netdev,
+						   adapter->num_tx_queues);
+		if (err)
+			goto err_set_queues;
 
-	err = netif_set_real_num_rx_queues(adapter->netdev,
-					   adapter->num_rx_queues);
-	if (err)
-		goto err_set_queues;
+		err = netif_set_real_num_rx_queues(adapter->netdev,
+						   adapter->num_rx_queues);
+		if (err)
+			goto err_set_queues;
+	}
 
 	/* From here on the code is the same as igb_up() */
 	clear_bit(__IGB_DOWN, &adapter->state);
 
-	for (i = 0; i < adapter->num_q_vectors; i++)
-		napi_enable(&(adapter->q_vector[i]->napi));
+	if (unlikely(!adapter->is_ecat)) {
+		for (i = 0; i < adapter->num_q_vectors; i++)
+			napi_enable(&(adapter->q_vector[i]->napi));
+	}
 
 	/* Clear any pending interrupts. */
 	rd32(E1000_TSICR);
@@ -4208,7 +4337,9 @@ static int __igb_open(struct net_device
 		wr32(E1000_CTRL_EXT, reg_data);
 	}
 
-	netif_tx_start_all_queues(netdev);
+	if (!adapter->is_ecat) {
+		netif_tx_start_all_queues(netdev);
+	}
 
 	if (!resuming)
 		pm_runtime_put(&pdev->dev);
@@ -4275,7 +4406,9 @@ static int __igb_close(struct net_device
 
 int igb_close(struct net_device *netdev)
 {
-	if (netif_device_present(netdev) || netdev->dismantle)
+	struct igb_adapter *adapter = netdev_priv(netdev);
+
+	if (adapter->is_ecat || netif_device_present(netdev) || netdev->dismantle)
 		return __igb_close(netdev, false);
 	return 0;
 }
@@ -4917,11 +5050,16 @@ static void igb_clean_tx_ring(struct igb
 	while (i != tx_ring->next_to_use) {
 		union e1000_adv_tx_desc *eop_desc, *tx_desc;
 
-		/* Free all the Tx ring sk_buffs or xdp frames */
-		if (tx_buffer->type == IGB_TYPE_SKB)
-			dev_kfree_skb_any(tx_buffer->skb);
-		else
-			xdp_return_frame(tx_buffer->xdpf);
+		/* Free all the Tx ring sk_buffs */
+		struct igb_adapter *adapter = netdev_priv(tx_ring->netdev);
+		if (unlikely(!adapter->is_ecat)) {
+			/* skb is reused in EtherCAT TX operation */
+			/* Free all the Tx ring sk_buffs or xdp frames */
+			if (tx_buffer->type == IGB_TYPE_SKB)
+				dev_kfree_skb_any(tx_buffer->skb);
+			else
+				xdp_return_frame(tx_buffer->xdpf);
+		}
 
 		/* unmap skb header data */
 		dma_unmap_single(tx_ring->dev,
@@ -5531,6 +5669,23 @@ static void igb_watchdog_task(struct wor
 
 	link = igb_has_link(adapter);
 
+	if (likely(adapter->is_ecat)) {
+		if (adapter->ecat_dev) {
+			ethercat_device_set_link(adapter->ecat_dev, link);
+		}
+	
+		if (!test_bit(__IGB_DOWN, &adapter->state)) {
+			mod_timer(&adapter->watchdog_timer, round_jiffies(jiffies + HZ));
+		}
+
+		adapter->link_speed = SPEED_100;
+	
+		spin_lock(&adapter->stats64_lock);
+		igb_update_stats(adapter);
+		spin_unlock(&adapter->stats64_lock);
+		return;
+	}
+
 	if (adapter->flags & IGB_FLAG_NEED_LINK_UPDATE) {
 		if (time_after(jiffies, (adapter->link_check_timeout + HZ)))
 			adapter->flags &= ~IGB_FLAG_NEED_LINK_UPDATE;
@@ -5771,7 +5926,11 @@ static void igb_update_ring_itr(struct i
 	 * ints/sec - ITR timer value of 120 ticks.
 	 */
 	if (adapter->link_speed != SPEED_1000) {
-		new_val = IGB_4K_ITR;
+		if (adapter->ecat_dev) {
+			new_val = IGB_20K_ITR;
+		} else {
+			new_val = IGB_4K_ITR;
+		}
 		goto set_itr_val;
 	}
 
@@ -6177,8 +6336,11 @@ static void igb_tx_olinfo_status(struct
 static int __igb_maybe_stop_tx(struct igb_ring *tx_ring, const u16 size)
 {
 	struct net_device *netdev = tx_ring->netdev;
+	struct igb_adapter *adapter = netdev_priv(netdev);
 
-	netif_stop_subqueue(netdev, tx_ring->queue_index);
+	if (!adapter->is_ecat) {
+		netif_stop_subqueue(netdev, tx_ring->queue_index);
+	}
 
 	/* Herbert's original patch had:
 	 *  smp_mb__after_netif_stop_queue();
@@ -6193,7 +6355,9 @@ static int __igb_maybe_stop_tx(struct ig
 		return -EBUSY;
 
 	/* A reprieve! */
-	netif_wake_subqueue(netdev, tx_ring->queue_index);
+	if (!adapter->is_ecat) {
+		netif_wake_subqueue(netdev, tx_ring->queue_index);
+	}
 
 	u64_stats_update_begin(&tx_ring->tx_syncp2);
 	tx_ring->tx_stats.restart_queue2++;
@@ -6222,6 +6386,7 @@ static int igb_tx_map(struct igb_ring *t
 	u32 tx_flags = first->tx_flags;
 	u32 cmd_type = igb_tx_cmd_type(skb, tx_flags);
 	u16 i = tx_ring->next_to_use;
+	struct igb_adapter *adapter = netdev_priv(tx_ring->netdev);
 
 	tx_desc = IGB_TX_DESC(tx_ring, i);
 
@@ -6288,7 +6453,9 @@ static int igb_tx_map(struct igb_ring *t
 	cmd_type |= size | IGB_TXD_DCMD;
 	tx_desc->read.cmd_type_len = cpu_to_le32(cmd_type);
 
-	netdev_tx_sent_queue(txring_txq(tx_ring), first->bytecount);
+	if (unlikely(!adapter->is_ecat)) {
+		netdev_tx_sent_queue(txring_txq(tx_ring), first->bytecount);
+	}
 
 	/* set the timestamp */
 	first->time_stamp = jiffies;
@@ -6316,8 +6483,13 @@ static int igb_tx_map(struct igb_ring *t
 	/* Make sure there is space in the ring for the next send. */
 	igb_maybe_stop_tx(tx_ring, DESC_NEEDED);
 
-	if (netif_xmit_stopped(txring_txq(tx_ring)) || !netdev_xmit_more()) {
+	if (likely(adapter->ecat_dev)) {
 		writel(i, tx_ring->tail);
+		wmb();
+	} else {
+		if (netif_xmit_stopped(txring_txq(tx_ring)) || !netdev_xmit_more()) {
+			writel(i, tx_ring->tail);
+		}
 	}
 	return 0;
 
@@ -6346,8 +6518,10 @@ dma_error:
 				 DMA_TO_DEVICE);
 	dma_unmap_len_set(tx_buffer, len, 0);
 
-	dev_kfree_skb_any(tx_buffer->skb);
-	tx_buffer->skb = NULL;
+	if (!adapter->is_ecat) {
+		dev_kfree_skb_any(tx_buffer->skb);
+		tx_buffer->skb = NULL;
+	}
 
 	tx_ring->next_to_use = i;
 
@@ -6472,6 +6646,7 @@ netdev_tx_t igb_xmit_frame_ring(struct s
 	u16 count = TXD_USE_COUNT(skb_headlen(skb));
 	__be16 protocol = vlan_get_protocol(skb);
 	u8 hdr_len = 0;
+	struct igb_adapter *adapter = netdev_priv(tx_ring->netdev);
 
 	/* need: 1 descriptor per page * PAGE_SIZE/IGB_MAX_DATA_PER_TXD,
 	 *       + 1 desc for skb_headlen/IGB_MAX_DATA_PER_TXD,
@@ -6495,38 +6670,39 @@ netdev_tx_t igb_xmit_frame_ring(struct s
 	first->bytecount = skb->len;
 	first->gso_segs = 1;
 
-	if (unlikely(skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP)) {
-		struct igb_adapter *adapter = netdev_priv(tx_ring->netdev);
+	if (unlikely(!adapter->is_ecat)) { 
+		if (unlikely(skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP)) {
 
-		if (adapter->tstamp_config.tx_type == HWTSTAMP_TX_ON &&
-		    !test_and_set_bit_lock(__IGB_PTP_TX_IN_PROGRESS,
-					   &adapter->state)) {
-			skb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;
-			tx_flags |= IGB_TX_FLAGS_TSTAMP;
-
-			adapter->ptp_tx_skb = skb_get(skb);
-			adapter->ptp_tx_start = jiffies;
-			if (adapter->hw.mac.type == e1000_82576)
-				schedule_work(&adapter->ptp_tx_work);
-		} else {
-			adapter->tx_hwtstamp_skipped++;
+			if (adapter->tstamp_config.tx_type == HWTSTAMP_TX_ON &&
+					!test_and_set_bit_lock(__IGB_PTP_TX_IN_PROGRESS,
+						&adapter->state)) {
+				skb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;
+				tx_flags |= IGB_TX_FLAGS_TSTAMP;
+
+				adapter->ptp_tx_skb = skb_get(skb);
+				adapter->ptp_tx_start = jiffies;
+				if (adapter->hw.mac.type == e1000_82576)
+					schedule_work(&adapter->ptp_tx_work);
+			} else {
+				adapter->tx_hwtstamp_skipped++;
+			}
 		}
-	}
 
-	if (skb_vlan_tag_present(skb)) {
-		tx_flags |= IGB_TX_FLAGS_VLAN;
-		tx_flags |= (skb_vlan_tag_get(skb) << IGB_TX_FLAGS_VLAN_SHIFT);
-	}
-
-	/* record initial flags and protocol */
-	first->tx_flags = tx_flags;
-	first->protocol = protocol;
+		if (skb_vlan_tag_present(skb)) {
+			tx_flags |= IGB_TX_FLAGS_VLAN;
+			tx_flags |= (skb_vlan_tag_get(skb) << IGB_TX_FLAGS_VLAN_SHIFT);
+		}
 
-	tso = igb_tso(tx_ring, first, &hdr_len);
-	if (tso < 0)
-		goto out_drop;
-	else if (!tso)
-		igb_tx_csum(tx_ring, first);
+		/* record initial flags and protocol */
+		first->tx_flags = tx_flags;
+		first->protocol = protocol;
+
+		tso = igb_tso(tx_ring, first, &hdr_len);
+		if (tso < 0)
+			goto out_drop;
+		else if (!tso)
+			igb_tx_csum(tx_ring, first);
+	}
 
 	if (igb_tx_map(tx_ring, first, hdr_len))
 		goto cleanup_tx_tstamp;
@@ -6534,12 +6710,12 @@ netdev_tx_t igb_xmit_frame_ring(struct s
 	return NETDEV_TX_OK;
 
 out_drop:
-	dev_kfree_skb_any(first->skb);
-	first->skb = NULL;
+	if (!adapter->is_ecat) {
+		dev_kfree_skb_any(first->skb);
+		first->skb = NULL;
+	}
 cleanup_tx_tstamp:
-	if (unlikely(tx_flags & IGB_TX_FLAGS_TSTAMP)) {
-		struct igb_adapter *adapter = netdev_priv(tx_ring->netdev);
-
+	if (unlikely(!adapter->is_ecat && (tx_flags & IGB_TX_FLAGS_TSTAMP))) {
 		dev_kfree_skb_any(adapter->ptp_tx_skb);
 		adapter->ptp_tx_skb = NULL;
 		if (adapter->hw.mac.type == e1000_82576)
@@ -6989,20 +7165,10 @@ static void igb_extts(struct igb_adapter
 
 static void igb_tsync_interrupt(struct igb_adapter *adapter)
 {
-	const u32 mask = (TSINTR_SYS_WRAP | E1000_TSICR_TXTS |
-			  TSINTR_TT0 | TSINTR_TT1 |
-			  TSINTR_AUTT0 | TSINTR_AUTT1);
 	struct e1000_hw *hw = &adapter->hw;
 	u32 tsicr = rd32(E1000_TSICR);
 	struct ptp_clock_event event;
 
-	if (hw->mac.type == e1000_82580) {
-		/* 82580 has a hardware bug that requires an explicit
-		 * write to clear the TimeSync interrupt cause.
-		 */
-		wr32(E1000_TSICR, tsicr & mask);
-	}
-
 	if (tsicr & TSINTR_SYS_WRAP) {
 		event.type = PTP_CLOCK_PPS;
 		if (adapter->ptp_caps.pps)
@@ -7089,11 +7255,16 @@ static void igb_write_itr(struct igb_q_v
 static irqreturn_t igb_msix_ring(int irq, void *data)
 {
 	struct igb_q_vector *q_vector = data;
+	struct igb_adapter *adapter = q_vector->adapter;
 
 	/* Write the ITR value calculated from the previous interrupt. */
 	igb_write_itr(q_vector);
 
-	napi_schedule(&q_vector->napi);
+	if (likely(adapter->is_ecat)) {
+		igb_poll(&q_vector->napi, 64);
+	} else {
+		napi_schedule(&q_vector->napi);
+	}
 
 	return IRQ_HANDLED;
 }
@@ -8134,7 +8305,11 @@ static irqreturn_t igb_intr_msi(int irq,
 	if (icr & E1000_ICR_TS)
 		igb_tsync_interrupt(adapter);
 
-	napi_schedule(&q_vector->napi);
+	if (likely(adapter->is_ecat)) {
+		igb_poll(&q_vector->napi, 64);
+	} else {
+		napi_schedule(&q_vector->napi);
+	}
 
 	return IRQ_HANDLED;
 }
@@ -8180,7 +8355,11 @@ static irqreturn_t igb_intr(int irq, voi
 	if (icr & E1000_ICR_TS)
 		igb_tsync_interrupt(adapter);
 
-	napi_schedule(&q_vector->napi);
+	if (likely(adapter->is_ecat)) {
+		igb_poll(&q_vector->napi, 64);
+	} else {
+		napi_schedule(&q_vector->napi);
+	}
 
 	return IRQ_HANDLED;
 }
@@ -8241,7 +8420,7 @@ static int igb_poll(struct napi_struct *
 	/* Exit the polling mode, but don't re-enable interrupts if stack might
 	 * poll us due to busy-polling
 	 */
-	if (likely(napi_complete_done(napi, work_done)))
+	if (likely(q_vector->adapter->is_ecat) || likely(napi_complete_done(napi, work_done)))
 		igb_ring_irq_enable(q_vector);
 
 	return work_done;
@@ -8292,11 +8471,13 @@ static bool igb_clean_tx_irq(struct igb_
 		total_bytes += tx_buffer->bytecount;
 		total_packets += tx_buffer->gso_segs;
 
-		/* free the skb */
-		if (tx_buffer->type == IGB_TYPE_SKB)
-			napi_consume_skb(tx_buffer->skb, napi_budget);
-		else
-			xdp_return_frame(tx_buffer->xdpf);
+		if (unlikely(!adapter->is_ecat)) {
+			/* free the skb */
+			if (tx_buffer->type == IGB_TYPE_SKB)
+				napi_consume_skb(tx_buffer->skb, napi_budget);
+			else
+				xdp_return_frame(tx_buffer->xdpf);
+		}
 
 		/* unmap skb header data */
 		dma_unmap_single(tx_ring->dev,
@@ -8345,8 +8526,10 @@ static bool igb_clean_tx_irq(struct igb_
 		budget--;
 	} while (likely(budget));
 
-	netdev_tx_completed_queue(txring_txq(tx_ring),
-				  total_packets, total_bytes);
+	if (unlikely(!adapter->is_ecat)) {
+		netdev_tx_completed_queue(txring_txq(tx_ring),
+					  total_packets, total_bytes);
+	}
 	i += tx_ring->count;
 	tx_ring->next_to_clean = i;
 	u64_stats_update_begin(&tx_ring->tx_syncp);
@@ -8356,7 +8539,8 @@ static bool igb_clean_tx_irq(struct igb_
 	q_vector->tx.total_bytes += total_bytes;
 	q_vector->tx.total_packets += total_packets;
 
-	if (test_bit(IGB_RING_FLAG_TX_DETECT_HANG, &tx_ring->flags)) {
+	if (unlikely(!adapter->is_ecat &&
+			test_bit(IGB_RING_FLAG_TX_DETECT_HANG, &tx_ring->flags))) {
 		struct e1000_hw *hw = &adapter->hw;
 
 		/* Detect a transmit hang in hardware, this serializes the
@@ -8399,7 +8583,7 @@ static bool igb_clean_tx_irq(struct igb_
 	}
 
 #define TX_WAKE_THRESHOLD (DESC_NEEDED * 2)
-	if (unlikely(total_packets &&
+	if (unlikely(!adapter->is_ecat && total_packets &&
 	    netif_carrier_ok(tx_ring->netdev) &&
 	    igb_desc_unused(tx_ring) >= TX_WAKE_THRESHOLD)) {
 		/* Make sure that anybody stopping the queue after this
@@ -8533,7 +8717,11 @@ static struct sk_buff *igb_construct_skb
 	net_prefetch(xdp->data);
 
 	/* allocate a skb to store the frags */
-	skb = napi_alloc_skb(&rx_ring->q_vector->napi, IGB_RX_HDR_LEN);
+	if (likely(rx_ring->q_vector->adapter->is_ecat)) {
+		skb = dev_alloc_skb(IGB_RX_HDR_LEN);
+	} else {
+		skb = napi_alloc_skb(&rx_ring->q_vector->napi, IGB_RX_HDR_LEN);
+	}
 	if (unlikely(!skb))
 		return NULL;
 
@@ -8893,14 +9081,12 @@ static void igb_put_rx_buffer(struct igb
 
 static int igb_clean_rx_irq(struct igb_q_vector *q_vector, const int budget)
 {
-	unsigned int total_bytes = 0, total_packets = 0;
 	struct igb_adapter *adapter = q_vector->adapter;
 	struct igb_ring *rx_ring = q_vector->rx.ring;
-	u16 cleaned_count = igb_desc_unused(rx_ring);
 	struct sk_buff *skb = rx_ring->skb;
-	int cpu = smp_processor_id();
+	unsigned int total_bytes = 0, total_packets = 0;
+	u16 cleaned_count = igb_desc_unused(rx_ring);
 	unsigned int xdp_xmit = 0;
-	struct netdev_queue *nq;
 	struct xdp_buff xdp;
 	u32 frame_sz = 0;
 	int rx_buf_pgcnt;
@@ -8950,54 +9136,69 @@ static int igb_clean_rx_irq(struct igb_q
 			size -= ts_hdr_len;
 		}
 
-		/* retrieve a buffer from the ring */
-		if (!skb) {
-			unsigned char *hard_start = pktbuf - igb_rx_offset(rx_ring);
-			unsigned int offset = pkt_offset + igb_rx_offset(rx_ring);
-
-			xdp_prepare_buff(&xdp, hard_start, offset, size, true);
-			xdp_buff_clear_frags_flag(&xdp);
-#if (PAGE_SIZE > 4096)
-			/* At larger PAGE_SIZE, frame_sz depend on len size */
-			xdp.frame_sz = igb_rx_frame_truesize(rx_ring, size);
-#endif
-			skb = igb_run_xdp(adapter, rx_ring, &xdp);
-		}
+		if (likely(adapter->is_ecat)) {
+			if (size > 0) {
+				prefetch(pktbuf);
+				ethercat_device_receive(adapter->ecat_dev, pktbuf, size);
+			}
+			igb_reuse_rx_page(rx_ring, rx_buffer);
+		} else {
+			/* retrieve a buffer from the ring */
+			if (!skb) {
+				unsigned char *hard_start = pktbuf - igb_rx_offset(rx_ring);
+				unsigned int offset = pkt_offset + igb_rx_offset(rx_ring);
+
+				xdp_prepare_buff(&xdp, hard_start, offset, size, true);
+				xdp_buff_clear_frags_flag(&xdp);
+	#if (PAGE_SIZE > 4096)
+				/* At larger PAGE_SIZE, frame_sz depend on len size */
+				xdp.frame_sz = igb_rx_frame_truesize(rx_ring, size);
+	#endif
+				skb = igb_run_xdp(adapter, rx_ring, &xdp);
+			}
 
-		if (IS_ERR(skb)) {
-			unsigned int xdp_res = -PTR_ERR(skb);
+			if (IS_ERR(skb)) {
+				unsigned int xdp_res = -PTR_ERR(skb);
 
-			if (xdp_res & (IGB_XDP_TX | IGB_XDP_REDIR)) {
-				xdp_xmit |= xdp_res;
-				igb_rx_buffer_flip(rx_ring, rx_buffer, size);
-			} else {
+				if (xdp_res & (IGB_XDP_TX | IGB_XDP_REDIR)) {
+					xdp_xmit |= xdp_res;
+					igb_rx_buffer_flip(rx_ring, rx_buffer, size);
+				} else {
+					rx_buffer->pagecnt_bias++;
+				}
+				total_packets++;
+				total_bytes += size;
+			} else if (skb)
+				igb_add_rx_frag(rx_ring, rx_buffer, skb, size);
+			else if (ring_uses_build_skb(rx_ring))
+				skb = igb_build_skb(rx_ring, rx_buffer, &xdp,
+						    timestamp);
+			else
+				skb = igb_construct_skb(rx_ring, rx_buffer,
+							&xdp, timestamp);
+
+			/* exit if we failed to retrieve a buffer */
+			if (!skb) {
+				rx_ring->rx_stats.alloc_failed++;
 				rx_buffer->pagecnt_bias++;
+				break;
 			}
-			total_packets++;
-			total_bytes += size;
-		} else if (skb)
-			igb_add_rx_frag(rx_ring, rx_buffer, skb, size);
-		else if (ring_uses_build_skb(rx_ring))
-			skb = igb_build_skb(rx_ring, rx_buffer, &xdp,
-					    timestamp);
-		else
-			skb = igb_construct_skb(rx_ring, rx_buffer,
-						&xdp, timestamp);
 
-		/* exit if we failed to retrieve a buffer */
-		if (!skb) {
-			rx_ring->rx_stats.alloc_failed++;
-			rx_buffer->pagecnt_bias++;
-			break;
+			igb_put_rx_buffer(rx_ring, rx_buffer, rx_buf_pgcnt);
 		}
 
-		igb_put_rx_buffer(rx_ring, rx_buffer, rx_buf_pgcnt);
 		cleaned_count++;
 
 		/* fetch next buffer in frame if non-eop */
 		if (igb_is_non_eop(rx_ring, rx_desc))
 			continue;
 
+		if (likely(adapter->is_ecat)) {
+			total_bytes += size;
+			total_packets++;
+			continue;
+		}
+
 		/* verify the packet layout is correct */
 		if (igb_cleanup_headers(rx_ring, rx_desc, skb)) {
 			skb = NULL;
@@ -9028,10 +9229,7 @@ static int igb_clean_rx_irq(struct igb_q
 	if (xdp_xmit & IGB_XDP_TX) {
 		struct igb_ring *tx_ring = igb_xdp_tx_queue_mapping(adapter);
 
-		nq = txring_txq(tx_ring);
-		__netif_tx_lock(nq, cpu);
 		igb_xdp_ring_update_tail(tx_ring);
-		__netif_tx_unlock(nq);
 	}
 
 	u64_stats_update_begin(&rx_ring->rx_syncp);
@@ -9206,6 +9404,79 @@ static int igb_ioctl(struct net_device *
 		return igb_ptp_get_ts_config(netdev, ifr);
 	case SIOCSHWTSTAMP:
 		return igb_ptp_set_ts_config(netdev, ifr);
+	case ETHERCAT_DEVICE_NET_DEVICE_DO_POLL: {
+		struct igb_adapter *adapter = netdev_priv(netdev);
+		struct igb_q_vector *q_vector = adapter->q_vector[0];
+		int budget = 64;
+		bool clean_complete = true;
+
+		if (!adapter->is_ecat) {
+			return -EOPNOTSUPP;
+		}
+
+		if (q_vector->tx.ring) {
+			clean_complete = igb_clean_tx_irq(q_vector, budget);
+		}
+
+		if (q_vector->rx.ring) {
+			int cleaned = igb_clean_rx_irq(q_vector, budget);
+
+			if (cleaned >= budget) 
+				clean_complete = false;
+		}
+		if (!clean_complete) 
+			return 1;
+
+		return 0;
+	}
+	case ETHERCAT_DEVICE_NET_DEVICE_SET_POLLING: {
+		int do_reopen = ethercat_polling != 1;
+		struct igb_adapter *adapter = netdev_priv(netdev);
+		if (!adapter->is_ecat) {
+			return -EOPNOTSUPP;
+		}
+
+		if (do_reopen) {
+			igb_close(netdev);
+		}
+
+		ethercat_polling = 1;
+
+		if (do_reopen) {
+			igb_open(netdev);
+		}
+		return 1;
+	}
+	case ETHERCAT_DEVICE_NET_DEVICE_RESET_POLLING: {
+		int do_reopen = ethercat_polling != 0;
+		struct igb_adapter *adapter = netdev_priv(netdev);
+		if (!adapter->is_ecat) {
+			return -EOPNOTSUPP;
+		}
+
+		if (do_reopen) {
+			igb_close(netdev);
+		}
+
+		ethercat_polling = 0;
+
+		if (do_reopen) {
+			igb_open(netdev);
+		}
+		return 1;
+	}
+	case ETHERCAT_DEVICE_NET_DEVICE_GET_POLLING: {
+		struct igb_adapter *adapter = netdev_priv(netdev);
+		if (!adapter->is_ecat) {
+			return -EOPNOTSUPP;
+		}
+
+		if (ethercat_polling == 0) {
+			return 0;
+		} 
+
+		return 1;
+	}
 	default:
 		return -EOPNOTSUPP;
 	}
@@ -9387,7 +9658,7 @@ static int __igb_shutdown(struct pci_dev
 	rtnl_lock();
 	netif_device_detach(netdev);
 
-	if (netif_running(netdev))
+	if (adapter->is_ecat || netif_running(netdev))
 		__igb_close(netdev, true);
 
 	igb_ptp_suspend(adapter);
@@ -9672,10 +9943,6 @@ static void igb_io_resume(struct pci_dev
 	struct igb_adapter *adapter = netdev_priv(netdev);
 
 	if (netif_running(netdev)) {
-		if (!test_bit(__IGB_DOWN, &adapter->state)) {
-			dev_dbg(&pdev->dev, "Resuming from non-fatal error, do nothing.\n");
-			return;
-		}
 		if (igb_up(adapter)) {
 			dev_err(&pdev->dev, "igb_up failed after reset\n");
 			return;
diff -rup /home_local/burger_r/opensuse/kernel/drivers/net/ethernet/intel/igb/Makefile 6.4.0/intel/igb/Makefile
--- /home_local/burger_r/opensuse/kernel/drivers/net/ethernet/intel/igb/Makefile	2024-11-28 06:18:28.234435315 +0100
+++ 6.4.0/intel/igb/Makefile	2024-11-27 12:32:25.193223027 +0100
@@ -4,8 +4,12 @@
 # Makefile for the Intel(R) 82575 PCI-Express ethernet driver
 #
 
-obj-$(CONFIG_IGB) += igb.o
+obj-$(CONFIG_IGB) += igb-ethercat.o
 
-igb-objs := igb_main.o igb_ethtool.o e1000_82575.o \
+igb-ethercat-objs := igb_main.o igb_ethtool.o e1000_82575.o \
 	    e1000_mac.o e1000_nvm.o e1000_phy.o e1000_mbx.o \
-	    e1000_i210.o igb_ptp.o igb_hwmon.o
+	    e1000_i210.o igb_ptp.o igb_hwmon.o 
+
+EXTRA_CFLAGS=-I$(src)/../../../../../../
+KBUILD_EXTRA_SYMBOLS=$(src)/../../../../../../Module.symvers
+
